{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.probability import depth_categorical_VI\n",
    "from src.DUN.train_fc import train_fc_DUN\n",
    "from src.DUN.training_wrappers import DUN_VI\n",
    "from src.DUN.stochastic_fc_models import arq_uncert_fc_resnet, arq_uncert_fc_MLP\n",
    "from src.datasets.spirals_loader import make_spirals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "output_dim = 5\n",
    "width = 100\n",
    "n_layers = 10\n",
    "momentum = 0.9\n",
    "lr = 0.001\n",
    "wd = 0.0001\n",
    "n_labelled = 50\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mDUN learnt with marginal likelihood categorical output\u001b[0m\n",
      "    Total params: 0.10M\n"
     ]
    }
   ],
   "source": [
    "model = arq_uncert_fc_resnet(input_dim, output_dim, width, n_layers, w_prior=None, BMA_prior=False)\n",
    "prior_probs = [1 / (n_layers + 1)] * (n_layers + 1)\n",
    "prob_model = depth_categorical_VI(prior_probs, cuda=cuda)\n",
    "net = DUN_VI(model, prob_model, n_labelled, lr=lr, momentum=momentum, cuda=cuda, schedule=None, regression=False, pred_sig=None, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  restoring epoch: 996, lr: 0.001000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "net.load('saves_classification/DUN_spirals_2000_5_10_100_0.001_0.0001_1_50/0/50_knoqaw19/models/theta_last.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_spirals(n_samples=100, shuffle=True, noise=0.2, random_state=42, n_arms=5, start_angle=0, stop_angle=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([-2.64971411,  3.79224718])]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "[X_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966],\n",
       "        [0.5824, 0.0063, 0.3060, 0.0087, 0.0966]])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "net.predict(torch.Tensor([[-2.64971411,  3.79224718]]*100), get_std=False, return_model_std=False)"
   ]
  }
 ]
}